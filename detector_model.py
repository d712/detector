import numpy as np
import pandas as pd
import sys, os, pdb, joblib
import mediapipe as mp

from mediapipe.tasks.python import vision
import sklearn.pipeline


class DetectorModel:
    """
    
    A wrapper class that classifies pictures based on whether middle fingers are detected. Includes functions for model initiation for hand detection and gesture detection, data normalization, and prediction."""
    def __init__(self, mpdetector: vision.HandLandmarker, model: sklearn.pipeline.Pipeline, model_threshold: float, point2origin: int, point2y: int, point2xy: int, num_hand_landmarks: int) -> None:
        """
        Initiate the wrapper class and save internal states for model configurations for both hand detection and gesture detection.
        
            
        Parameters
        ----------
        mpdetector: vision.HandLandmarker. Google Mediapipe's hand detection model
        model: sklearn.pipeline.Pipeline. Multi-level perception model for gesture (middle finger) detection.
        model_threshold: float. The hand will be flagged for detected middle finger gesture if probability predicted from the model exceeds model threshold.
        point2origin: int. The point that needs to become the origin (0,0,0) after normalization. The point is one of the 21 hand landmarks from Mediapipe's hand detection.
        point2y: int. The point that needs to lie somewhere on the y axis at (0,y,0) after normalization. The point is one of the 21 hand landmarks from Mediapipe's hand detection.
        point2xy: int. The point that needs to lie somewhere on the xy-plane at (x,y,0) after normalization. The point is one of the 21 hand landmarks from Mediapipe's hand detection.
        num_hand_landmarks: int. Mediapipe's hand detection model uses 21 points/landmarks to define a hand.

        """

        self.detector = mpdetector
        self.model = model
        self.threshold = model_threshold
        self.point2origin = point2origin
        self.point2y = point2y
        self.point2xy = point2xy
        self.num_hand_landmarks = num_hand_landmarks
                
    def detection2obs(self, detection_result: vision.HandLandmarkerResult) -> list:
        """
        Given hand detection results generated by mediapipe, unpack and organize hand landmarks into list.
        
        Parameter
        ----------
        detection_result: vision.HandLandmarkerResult. Results of running hand detection on a picture using MediaPipe's hand detection model. Contains hand landmarks.

        Return
        ------
        obs_list: list. Information extracted from the detection results in the format of a list. Information includes hand (left hand = 1, right hand = 0), hand_score (The confidence score for the detected hand as a whole. Range: Between 0.0 and 1.0.), presence (How likely it is that a specific landmark (like wrist, fingertip) exists in the image. Range: [0.0, 1.0]), visibility (How visible or unobstructed a landmark is. Range: [0.0, 1.0]), and coordinates (3D coordinates of a landmark (x,y,z)).
        
        """
        # obs_list is a list that captures information on multiple hands in one picture. Each item within the list describe one hand. Length of list is equal to the number of hands in the picture.
        obs_list = []
        # for each hand in the picture
        for i in range(len(detection_result.hand_landmarks)):
            # unpacking detection_results
            hand = int(detection_result.handedness[i][0].category_name == 'Left')
            hand_score = detection_result.handedness[i][0].score
            hlm = detection_result.hand_landmarks
            hlm_list = [value for j in range(len(hlm[i])) for value in [hlm[i][j].presence, hlm[i][j].visibility, hlm[i][j].x, hlm[i][j].y, hlm[i][j].z]]
            # each item (obs) within the obs_list describe one hand
            obs = [hand, hand_score, *hlm_list]
            obs_list.append(obs)
        return(obs_list)
 
    def file2detection(self, data_location: str) -> pd.DataFrame | None:
        """
        Given image path, create normalized and reoriented hand landmarks.
        
        Parameter
        __________
        data_location: str. Path of the picture to be checked for gesture detection.

        Return
        ------
        A pd.dataframe that contains normalized and reoriented hand landmarks for all hands in the picture. 
        Returns None if MediaPipe detects no hands in the picture.
        """
        # Running MediaPipe model to detect hands in a picture
        image = mp.Image.create_from_file(data_location)
        detection_result = self.detector.detect(image)
        # Store information on hand landmarks for all hands in the picture in a pd.DataFrame, df. Number of rows in the df represents number of hands in the picture.
        df = pd.DataFrame(self.detection2obs(detection_result))
        if df.shape[0] == 0:
            return None
        # df has 2+5*21 columns for hand, hand_score, and 5 features per landmark for the 21 landmarks MediaPipe detects. The five features include presence, visibility, and the 3D coordinates (x,y,z)
        col_names = []
        for i in range(0, self.num_hand_landmarks):
            col_names += [f'presence_{i}',f'visibility_{i}',f'x_{i}',f'y_{i}',f'z_{i}']
        df.columns = ['hand','hand_score'] + col_names
        # Translate coordinates for all landmarks so that point2origin is the new origin with a coordinate of (0,0,0)
        df_clean = self.mk_orgn(df, self.point2origin)
        # rotate the coordinates for all landmarks so that point2y lies somewhere on the y axis at (0,y,0)
        df_clean = self.rtt_df_by_orgn(df_clean, self.point2y)
        # rotate the coordinates for all landmarks so that point2xy lies somewhere on the xy-plane at (x,y,0)       
        df_clean = self.rtt_df_by_y(df_clean, self.point2xy)
        # predict probability for positive cases of middle finger gesture using the gesture detection model
        probs = self.model.predict_proba(df_clean)[:,1]
        df_clean['probs'] = probs
        df_clean['data_location'] = data_location
        # flag the hand if probability predicted from the model exceeds model threshold
        df_clean['flag_pic'] = (probs >= self.threshold).sum()>0
        df_clean['flag_hand'] = probs >= self.threshold
        df_clean['filename'] = [data_location] * df_clean.shape[0]
        return df_clean

    def folder2df(self, data_folder_location: str) -> pd.DataFrame:
        """
        Given folder path, create a dataframe of normalized hand landmarks for all pictures in the folder.
        
        Parameter
        ----------
        data_folder_location: str. Path of the folder where uploaded picture(s) are stored.

        Return
        ------
        A dataframe that contains all the hand detection results (i.e., hand landmarks) from MediaPipe for all pictures in the folder and its subdirectories.
        """
        obs_df = pd.DataFrame()
        # process all files in the folder and its subdirectories
        for subdir, dirs, files in os.walk(data_folder_location):
            dirs[:] = [d for d in dirs if not d.startswith('.')]
            files = [f for f in files if not f.startswith('.')]
            # process each file in a directory
            for file in files:
                df = self.file2detection(os.path.join(subdir,file))
                # skip if no hands are detected in the picture
                if df is None:
                    continue
                obs_df = pd.concat([obs_df, df], ignore_index=True)
        return obs_df

    def mk_orgn(self, df: pd.DataFrame, point: int) -> pd.DataFrame:
        """
        Given a dataframe of 3D hand landmarks, translate all the landmarks so that the given point is at the origin (0, 0, 0).
        
        Parameters
        ----------
        df: pd.DataFrame. Contains 3D hand landmarks of hand(s).
        point: int. The point that needs to become the origin (0,0,0) after normalization. The point is one of the 21 hand landmarks from Mediapipe's hand detection.

        Return
        ------
        A dataframe with 3D coordinates where all the landmarks are translated so that the given point on each hand is at the origin (0,0,0).
        """
        # subtract the given point's coordinates from the coordinates of all points
        for coord in ['x', 'y', 'z']:
            cols = df.columns[df.columns.str.startswith(coord)]
            df[cols] = df[cols].apply(lambda col: col - df[f'{coord}_{point}'])
        return df

    def rtt_df_by_orgn(self, df: pd.DataFrame, point: int) -> pd.DataFrame:
        """
        Given a dataframe of 3D hand landmarks, rotate the all coordinates by the origin so that the vector that starts at the origin and ends at the specified point (one of the landmarks) is aligned with the y-axis.
        
        Parameters
        ----------
        df: pd.DataFrame. Contains 3D hand landmarks of hand(s).
        point: int. The point that needs to lie somewhere on the y axis at (0,y,0) after normalization. The point is one of the 21 hand landmarks from Mediapipe's hand detection.

        Return
        ------
        A dataframe with 3D coordinates where all the landmarks are rotated so that the given point on each hand lie somewhere on the y axis.
        """
        # retrieve given point's coordinate (x,y,z)
        point_2y_coords = df[df.columns[df.columns.str.endswith(f'_{point}')][2:5]].copy()
        # calculate length of vector <x,y,z>
        point_2y_coords['len'] = np.sqrt(point_2y_coords[f'x_{point}']**2 + point_2y_coords[f'y_{point}']**2 + point_2y_coords[f'z_{point}']**2)
        # convert <x,y,z> into a unit vector by normalizing it with vector length
        point_2y_coords_unit = point_2y_coords[point_2y_coords.columns[point_2y_coords.columns.str.endswith(f'_{point}')]].div(point_2y_coords['len'], axis=0)
        point_2y_coords.drop('len', axis=1,inplace=True)
        # Generate an axis to rotate the coordinates of the 21 landmarks around, for each hand in the df. The axis will be perpendicular to the plane defined by y-axis and normalized <x,y,z>. The axis is given by the cross product of these two vectors.
        axis = pd.DataFrame(np.cross(point_2y_coords_unit,(0,1,0)))
        # Generate the angle, theta, to rotate the coordinates of the 21 landmarks by, for each hand in the df. Theta will be the angle between y-axis and normalized <x,y,z>. Theta is a function of the dot product of these two vectors.
        theta = np.arccos(np.clip(np.dot(point_2y_coords_unit, (0,1,0)), -1.0, 1.0))
        # Given axis and theta, create a 3*3 rotation matrix R for each hand
        R = []
        # for each hand
        for i in range(len(axis)):
            # no rotation needed if <x,y,z> is already aligned with the y-axis, R becomes identity matrix
            if np.linalg.norm(axis.iloc[[i],:]) <1e-6:
                R.append(np.eye(3))
            else:
                u_axis = axis.iloc[[i],:]/np.linalg.norm(axis.iloc[[i],:])
                R.append(self.gn_rttn_mtx_pt(u_axis, theta[i]))
        df = df.reset_index(drop=True)
        # for each hand
        for j in range(df.shape[0]):
            # for each landmark, complete the rotation by multiplying the rotation matrix with the 3 coordinates of the landmark
            for i in range(0, self.num_hand_landmarks):
                df.loc[j,[f'x_{i}', f'y_{i}', f'z_{i}']] = R[j] @ df.loc[j,[f'x_{i}', f'y_{i}', f'z_{i}']]
        return df

    def gn_rttn_mtx_pt(self, axis: pd.DataFrame, theta: np.float64) -> np.ndarray:
        """
        Given an axis and an angle theta, generate the rotation matrix that rotates 3D coordinates by the axis by theta radians.

        Parameters
        ----------
        axis: pd.DataFrame. Contains 3 coordinates of a 3D vector to rotate all 21 of the hand landmarks of a single hand by.
        theta: np.float64. The radian to rotate all 21 of the hand landmarks of a single hand by.

        Return
        ------
        A 3*3 rotation matrix. The matrix will be used to transform the coordinates of all 21 landmarks of one hand via matrix multiplication.
        """
        axis_np = axis.iloc[0].to_numpy().astype(float)
        K = np.array([
            [0, -axis_np[2], axis_np[1]],
            [axis_np[2], 0, -axis_np[0]],
            [-axis_np[1], axis_np[0], 0]
        ])
        R = np.eye(3) + np.sin(theta)*K + (1 - np.cos(theta))*(K @ K)
        return R

    def rtt_df_by_y(self, df: pd.DataFrame, point: int) -> pd.DataFrame:
        """
        Given a dataframe of 3D hand landmarks, rotate the all coordinates by the Y axis so that a specified point (one of the landmarks) ends up on the xy-plane.
        
        Parameters
        ----------
        df: pd.DataFrame. Each row represents the 3D coordinates of hand landmarks.
        point: int. The point (one of the landmarks) that should be rotated so that it lands on the xy-plane.

        Return
        ------
        A pd.DataFrame that contains 3D coordinates of hand landmarks that have been rotated around the y-axis such that the specified point lands on the xy-plane.
        """
        # retrieve the coordinates (x,y,z) of the specified point for each hand
        point_2xy_coords = df[df.columns[df.columns.str.endswith(f'_{point}')][2:5]].copy()
        # generate theta, the angle to rotate the 3D coordinates by, for each hand
        point_2xy_coords['theta'] = point_2xy_coords.apply(lambda x: np.arctan2(x[2],x[0]), axis=1)
        Ry = []
        # for each hand, generate the rotation matrix used to transform coordinates of all 21 landmarks via matrix multiplication
        for i in range(len(point_2xy_coords)):
            Ry.append(self.gn_rttn_mtx_y(point_2xy_coords['theta'][i]))
        point_2xy_coords.drop('theta', axis=1, inplace=True)
        df = df.reset_index(drop=True)
        # for each hand
        for j in range(df.shape[0]):
            # for each landmark, transform 3D coordinates by multiplying the rotation matrix with them
            for i in range(0, self.num_hand_landmarks):
                df.loc[j,[f'x_{i}', f'y_{i}', f'z_{i}']] = Ry[j] @ df.loc[j,[f'x_{i}', f'y_{i}', f'z_{i}']]
        return df

    def gn_rttn_mtx_y(self, theta: np.float64) -> np.ndarray:
        """Given an angle, theta, create the 3*3 rotation matrix that rotates 3D coordinates by the Y axis by theta radians for one hand.
        
        Parameter
        ----------
        theta: np.float64. Rotation angle in radians.

        Return
        ------
        A 3*3 matrix in np.ndarray that rotates 3D coordinates by the Y axis by theta radians for all 21 landmarks of a hand.
        """
        R = np.array([
            [np.cos(theta), 0, np.sin(theta)],
            [0, 1, 0],
            [np.sin(-theta), 0, np.cos(-theta)]
        ])
        return R

